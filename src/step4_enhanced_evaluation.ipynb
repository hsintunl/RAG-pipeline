{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e86e36-42d7-44ca-9b90-f789c070f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced file: /Users/connie/Desktop/Fall 2025/LLM/Assignment2/data/evaluation/enhanced_experiment_generations.csv\n",
      "F1/EM results file: /Users/connie/Desktop/Fall 2025/LLM/Assignment2/results/evaluation_f1_em.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate as hf_evaluate\n",
    "\n",
    "ENHANCED_PATH = \"../data/evaluation/enhanced_experiment_generations.csv\"\n",
    "F1_EM_PATH    = \"../results/evaluation_f1_em.csv\"\n",
    "\n",
    "print(\"Enhanced file:\", os.path.abspath(ENHANCED_PATH))\n",
    "print(\"F1/EM results file:\", os.path.abspath(F1_EM_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a30da0-4922-4d91-b2c0-7c4914eeb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.read_csv(ENHANCED_PATH)\n",
    "\n",
    "pred_col = \"gen_enhanced_k5_persona_mpnet\"\n",
    "for col in [\"question\", \"answer\", pred_col]:\n",
    "    if col not in enhanced_df.columns:\n",
    "        raise ValueError(f\"Missing column in enhanced file: {col}\")\n",
    "\n",
    "answers = enhanced_df[\"answer\"].astype(str).tolist()\n",
    "preds   = enhanced_df[pred_col].fillna(\"\").astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bac294e-3ca7-4965-96a8-bf5c6eb977ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = hf_evaluate.load(\"squad\")\n",
    "f1_scores, em_scores = [], []\n",
    "for pred, truth in zip(preds, answers):\n",
    "    r = metric.compute(\n",
    "        predictions=[{\"prediction_text\": pred, \"id\": \"0\"}],\n",
    "        references=[{\"answers\": {\"text\": [truth], \"answer_start\": [0]}, \"id\": \"0\"}]\n",
    "    )\n",
    "    f1_scores.append(r[\"f1\"])\n",
    "    em_scores.append(r[\"exact_match\"])\n",
    "\n",
    "avg_f1 = float(np.mean(f1_scores))\n",
    "avg_em = float(np.mean(em_scores))\n",
    "\n",
    "row = {\n",
    "    \"Retrieval_K\": 5,\n",
    "    \"Prompt_Strategy\": \"enhanced-persona+qr+rerank\",\n",
    "    \"Embedding_Dim\": \"all-mpnet-base-v2\",\n",
    "    \"Avg_F1\": avg_f1,\n",
    "    \"Avg_EM\": avg_em,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae398998-4f90-41e5-b43c-3f0f1e0de6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated results saved to /Users/connie/Desktop/Fall 2025/LLM/Assignment2/results/evaluation_f1_em.csv\n",
      " Retrieval_K            Prompt_Strategy     Embedding_Dim    Avg_F1    Avg_EM\n",
      "           3                    persona all-mpnet-base-v2 44.691283 35.833333\n",
      "           5                      naive all-mpnet-base-v2 41.772417 32.500000\n",
      "           5                        cot all-mpnet-base-v2 38.412203 26.666667\n",
      "           5                    persona all-mpnet-base-v2 49.857943 40.000000\n",
      "           5 enhanced-persona+qr+rerank all-mpnet-base-v2 48.315471 38.333333\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(F1_EM_PATH):\n",
    "    results_df = pd.read_csv(F1_EM_PATH)\n",
    "else:\n",
    "    results_df = pd.DataFrame(columns=[\"Retrieval_K\",\"Prompt_Strategy\",\"Embedding_Dim\",\"Avg_F1\",\"Avg_EM\"])\n",
    "\n",
    "results_df = pd.concat([results_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "results_df = results_df.drop_duplicates(\n",
    "    subset=[\"Retrieval_K\",\"Prompt_Strategy\",\"Embedding_Dim\"], keep=\"last\"\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(F1_EM_PATH), exist_ok=True)\n",
    "results_df.to_csv(F1_EM_PATH, index=False)\n",
    "\n",
    "print(f\"Updated results saved to {os.path.abspath(F1_EM_PATH)}\")\n",
    "print(results_df.tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e42a8-1b91-4d06-9fba-157cf8883764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
